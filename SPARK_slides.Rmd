---
title: "SPARK Evaluation"
author: "Fil Babalievsky and Atishay Sehgal"
date: "8/2/2018"
output: beamer_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


```{r, echo=FALSE, message=FALSE, warning=FALSE}
setwd("~/Dropbox/New SI Stuff/SPARK Eval")
Final<-read.csv("Final_SPARK.csv")
library(stargazer)
```


## Background

- Dr. John Ratey: SPARK book, compiled evidence that aerobic exercise improves cognition

- Implemented in Naperville High for academically at-risk children, promising results but not randomized 

- Positive results from an RCT with obese young (7-11 year old) children in Georgia, bigger effects linked to longer exercise

- Borough Hall: Closer to a true randomized design than Naperville, very different population than Georgia, not pre-selected based on how likely they were to benefit


## Implementation

- One High School split a group of <100 ninth graders into 3 gym classes

- Arbitrarily split by Gym class, not based on systematic differences

- One quarter where all had same curriculum

- Aerobic exercise (heart rate near max) along with sports

- Implementation limited by state curriculum

- 3 days per week, 7 minutes in first quarter and 20 thereafter


## Empirical design

Differences in Differences: Do SPARK kids' scores grow more from Marking Period 1 to Marking Periods 2, 3, 4? Is this different in different classes?

- First: 

\[\Delta_{i,s,m}=\alpha_m+\beta_m \cdot SPARK_i\]

- Second: Split by classes

\[\Delta_{i,s,m}=\sum_j\alpha_{j,m}+\sum_j\beta_{j,m} \cdot SPARK_{i,j}\]


## Results: Simple Design

How to read this table: a score of 2.3 in the first column and row means that SPARK kids' scores improved by 2.3 points relative to non-SPARK kids from MP1 to MP2. A score of 0.5 in the second column means that SPARK scores went up by 0.5 points from MP1 to MP3 (it is not cumulative.)

```{r, results='asis', message=FALSE, echo=FALSE}
lm1<-lm(diff1~Spark,data=Final)
lm2<-lm(diff2~Spark,data=Final)
lm3<-lm(diff3~Spark,data=Final)
stargazer(lm1, lm2, lm3, type = "latex" , header=FALSE, column.labels = c("MP1 to MP2", "MP1 to MP3", "MP1 to MP4"), dep.var.labels.include = FALSE, column.sep.width = "0.5pt", font.size="tiny")
```

## Results: Class effects

How to read this table: Same as before, but broken up by class in the first 3 rows

```{r, results='asis', message=FALSE, echo=FALSE}
lm1a<-lm(diff1~Spark_math+Spark_sci+Spark_eng+math+eng,data=Final)
lm2a<-lm(diff2~Spark_math+Spark_sci+Spark_eng+math+eng,data=Final)
lm3a<-lm(diff3~Spark_math+Spark_sci+Spark_eng+math+eng,data=Final)
stargazer(lm1a, lm2a, lm3a, type = "latex" , header=FALSE, column.labels = c("MP1 to MP2", "MP1 to MP3", "MP1 to MP4"), dep.var.labels.include = FALSE, column.sep.width = "0.5pt", font.size="tiny")
```

## Interpretation

- Coefficients are points out of 100, so the coefficient of 2.8 on the 4th quarter math results means that SPARK kids had >0.28 grade levels of growth compared to non-SPARK

- Not huge and not as consistent as we would like, but still interesting

- Generally larger for math, in line with prior studies

- Hints that Georgia results could scale and that Naperville results could hold


## Going forward

Ideally:

- Large scale RCT (maybe randomly assign all SI High School gym classes to SPARK or non-SPARK)

- Get as much leeway as possible from State Education Dept

- Test for heterogeneous effects: maybe measure baseline academic performance and fitness from kids, test if effects are bigger for less fit or lower scoring kids

- Pre register the study for greater credibility and visibility

- Post code publicly on GitHub (best practice, lends credibility and lets others check our work)


## Possible Interest

- The prospect of running an RCT with thousands of students ought to make academics salivate

- We have offered some suggestions for how to run a larger study but it would be good to bring in full time researchers who specialize in this


## Who to work with

- J-PAL North America? Prominent team of economists, focused on randomization, big on contributing to public policy

- EdLabs? Sort of in turmoil at the moment, and their director wouldn't talk to us last time. Would have been the most logical choice until March 2018; avoid until/unless they work out their issues

- Sue Dynarski? Michigan education economist noted for public outreach (maintains a colorful Twitter page), fitness enthusiast




